{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4I8HKF9qP3RQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
            "[Open3D INFO] WebRTC GUI backend enabled.\n",
            "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
          ]
        }
      ],
      "source": [
        "from model.treemeshgpt_inference import TreeMeshGPT\n",
        "import os\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from pathlib import Path\n",
        "from fns import center_vertices, normalize_vertices_scale, str2bool\n",
        "import trimesh\n",
        "import pyvista as pv\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hbF-JZXTaeG"
      },
      "outputs": [],
      "source": [
        "VERSION = \"7bit\"\n",
        "CKPT_PATH = \"./checkpoints/treemeshgpt_7bit.pt\"\n",
        "MESH_PATH =  \"demo/luma_cat.glb\"\n",
        "MESH_PATH =  \"demo/FullMesh_1Hole_SplitDisk.obj\"\n",
        "#MESH_PATH =  \"demo/FullMesh_1Hole.obj\"\n",
        "#MESH_PATH =  \"demo/FullMesh.obj\"\n",
        "MESH_PATH =  \"demo/FullMesh_1Hole-2.obj\"\n",
        "\n",
        "#MESH_PATH = \"demo/Mesh2_DiskHole.obj\"\n",
        "#MESH_PATH = \"demo/Mesh2_Hole.obj\"\n",
        "MESH_PATH = \"demo/Mesh2.obj\"\n",
        "MESH_PATH = \"demo/objaverse_pig_CC0_Decim_2k.obj\"\n",
        "\n",
        "OUTPUT_DIR=\"./output\"\n",
        "\n",
        "DECIMATION = True\n",
        "DECIMATION_TARGET_NFACES = 5000\n",
        "DECIMATION_BOUNDARY_DELETION = True\n",
        "\n",
        "SAMPLING = \"uniform\" if VERSION == \"7bit\" else \"fps\"\n",
        "#SAMPLING = \"keep_vertices\"\n",
        "\n",
        "if not os.path.exists(\"./output\") :\n",
        "  os.mkdir(\"./output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1-o0138gTzeK"
      },
      "outputs": [],
      "source": [
        "# Set up model\n",
        "transformer = TreeMeshGPT(quant_bit = 7 if VERSION == \"7bit\" else 9, max_seq_len=13000) # can set higher max_seq_len if GPU is L4 or A100\n",
        "transformer.load(CKPT_PATH)\n",
        "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
        "transformer = accelerator.prepare(transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSSg1z1rVzGZ",
        "outputId": "42c374cd-402e-4676-f653-83169368c9bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mesh is decimated to 2000 faces\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and normalize mesh\n",
        "mesh = o3d.io.read_triangle_mesh(MESH_PATH)\n",
        "vertices = np.asarray(mesh.vertices)\n",
        "vertices = center_vertices(vertices)\n",
        "vertices = normalize_vertices_scale(vertices)\n",
        "vertices = np.clip(vertices, a_min=-0.5, a_max = 0.5)\n",
        "triangles = np.asarray(mesh.triangles)\n",
        "\n",
        "mesh = o3d.geometry.TriangleMesh()\n",
        "mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
        "mesh.triangles = o3d.utility.Vector3iVector(triangles)\n",
        "\n",
        "# Mesh decimation\n",
        "if DECIMATION:\n",
        "    n_triangles = min(DECIMATION_TARGET_NFACES, len(triangles))\n",
        "    faces_pyvista = np.hstack([np.full((triangles.shape[0], 1), 3), triangles]).astype(np.int64).flatten()\n",
        "    mesh = pv.PolyData(vertices, faces_pyvista)\n",
        "    decimated_mesh = mesh.decimate_pro(1-n_triangles/len(triangles), boundary_vertex_deletion=DECIMATION_BOUNDARY_DELETION)\n",
        "    decimated_vertices = np.array(decimated_mesh.points)\n",
        "    decimated_faces = np.array(decimated_mesh.faces).reshape(-1, 4)[:, 1:]  # Remove leading '3' per triangle\n",
        "    mesh = o3d.geometry.TriangleMesh()\n",
        "    mesh.vertices = o3d.utility.Vector3dVector(decimated_vertices)\n",
        "    mesh.triangles = o3d.utility.Vector3iVector(decimated_faces)\n",
        "    print(\"Mesh is decimated to {} faces\".format(len(decimated_faces)))\n",
        "else:\n",
        "    print(\"Sampling from original mesh with {} faces\".format(len(triangles)))\n",
        "\n",
        "o3d.io.write_triangle_mesh(OUTPUT_DIR+\"/\"+\"normalized_\"+os.path.split(MESH_PATH)[1], mesh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "us6-7u4VULt5"
      },
      "outputs": [],
      "source": [
        "# Point cloud sampling\n",
        "if SAMPLING == \"uniform\":\n",
        "    pc = mesh.sample_points_uniformly(number_of_points=8192)\n",
        "    o3d.io.write_point_cloud(OUTPUT_DIR+\"/\"+\"Sampling_Uniform_\"+os.path.split(MESH_PATH)[1]+\".ply\", pc)\n",
        "elif SAMPLING == \"fps\":\n",
        "    pc = mesh.sample_points_uniformly(number_of_points=8192*10)\n",
        "    pc_array = np.asarray(pc.points)\n",
        "    pc = o3d.geometry.PointCloud()\n",
        "    pc.points = o3d.utility.Vector3dVector(pc_array)\n",
        "    pc = pc.farthest_point_down_sample(8192//2)\n",
        "    o3d.io.write_point_cloud(OUTPUT_DIR+\"/\"+\"Sampling_FPS_\"+os.path.split(MESH_PATH)[1]+\".ply\", pc)\n",
        "elif SAMPLING == \"keep_vertices\" :\n",
        "    pc = o3d.geometry.PointCloud()\n",
        "    pc.points = mesh.vertices\n",
        "    o3d.io.write_point_cloud(OUTPUT_DIR+\"/\"+\"Sampling_KeepVertices_\"+os.path.split(MESH_PATH)[1]+\".ply\", pc)\n",
        "pc_array = np.asarray(pc.points)\n",
        "pc = torch.tensor(pc_array).unsqueeze(0).float().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SihYiRocVO1c",
        "outputId": "87bf4332-6ecd-475c-c8bb-ebf5fb62beaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequence length: 2351/13000 | Stack length: 830 "
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m accelerator.autocast(), torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     out_faces = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\TreeMeshGPT-RAQ\\model\\custom_transformers_inference.py:74\u001b[39m, in \u001b[36meval_decorator.<locals>.inner\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m was_training = \u001b[38;5;28mself\u001b[39m.training\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m.eval()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m out = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mself\u001b[39m.train(was_training)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\condaEnvs\\tmgpt\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\TreeMeshGPT-RAQ\\model\\treemeshgpt_inference.py:204\u001b[39m, in \u001b[36mTreeMeshGPT.generate\u001b[39m\u001b[34m(self, pc, n)\u001b[39m\n\u001b[32m    201\u001b[39m acc_fea = pack([acc_fea, fea], \u001b[33m'\u001b[39m\u001b[33mb * d\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]            \n\u001b[32m    203\u001b[39m te = \u001b[38;5;28mself\u001b[39m.adjust_temperature(\u001b[38;5;28mlen\u001b[39m(stack))        \n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m xyz_res, eos, cache = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc_fea\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mte\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xyz_res.sum() != -\u001b[32m3\u001b[39m:\n\u001b[32m    207\u001b[39m     cur_face = torch.cat([cur_edges, xyz_res], dim=-\u001b[32m1\u001b[39m).reshape(-\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m)[\u001b[32m0\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\TreeMeshGPT-RAQ\\model\\treemeshgpt_inference.py:328\u001b[39m, in \u001b[36mTreeMeshGPT.predict\u001b[39m\u001b[34m(self, acc_fea, t, init_mask, first, kv_cache)\u001b[39m\n\u001b[32m    326\u001b[39m res, intermediates = \u001b[38;5;28mself\u001b[39m.decoder(acc_fea, cache = kv_cache, return_hiddens = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    327\u001b[39m res = res[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m xyz, eos = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_xyz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdequantize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtopk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xyz.unsqueeze(\u001b[32m0\u001b[39m), eos, intermediates\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\TreeMeshGPT-RAQ\\model\\treemeshgpt_inference.py:281\u001b[39m, in \u001b[36mTreeMeshGPT.predict_xyz\u001b[39m\u001b[34m(self, res, dequantize, top_k, temperature, init_mask, first)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# Top-k sampling: Get top-k probabilities and their corresponding indices\u001b[39;00m\n\u001b[32m    280\u001b[39m topk_probs_z, topk_indices_z = torch.topk(probs_z, k=top_k, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_bit\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtopk_indices_z\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m.n += \u001b[32m0.001\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m topk_indices_z[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m] ==  \u001b[32m2\u001b[39m**\u001b[38;5;28mself\u001b[39m.quant_bit + \u001b[32m1\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\condaEnvs\\tmgpt\\Lib\\site-packages\\torch\\_tensor.py:1178\u001b[39m, in \u001b[36mTensor.__contains__\u001b[39m\u001b[34m(self, element)\u001b[39m\n\u001b[32m   1173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.\u001b[34m__contains__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, element)\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   1175\u001b[39m     element, (torch.Tensor, Number, torch.SymInt, torch.SymFloat, torch.SymBool)\n\u001b[32m   1176\u001b[39m ):\n\u001b[32m   1177\u001b[39m     \u001b[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1181\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1182\u001b[39m )\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Generation\n",
        "with accelerator.autocast(), torch.no_grad():\n",
        "    out_faces = transformer.generate(pc,n = 0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9anVC8oWmwU"
      },
      "outputs": [],
      "source": [
        "vertices = out_faces.view(-1, 3).cpu().numpy()\n",
        "n = vertices.shape[0]\n",
        "faces = torch.arange(1, n + 1).view(-1, 3).numpy()\n",
        "\n",
        "with open(OUTPUT_DIR+\"/\"+\"GeneratedVertices_\"+os.path.split(MESH_PATH)[1], \"w\") as file :\n",
        "  for vertex in vertices :\n",
        "    file.write(f\"v  {vertex[0]}  {vertex[1]}  {vertex[2]}\\n\")\n",
        "\n",
        "if min(min(faces.tolist())) == 1:\n",
        "    faces = (np.array(faces) - 1)\n",
        "\n",
        "# Remove collapsed triangles and duplicates\n",
        "p0 = vertices[faces[:, 0]]\n",
        "p1 = vertices[faces[:, 1]]\n",
        "p2 = vertices[faces[:, 2]]\n",
        "collapsed_mask = np.all(p0 == p1, axis=1) | np.all(p0 == p2, axis=1) | np.all(p1 == p2, axis=1)\n",
        "faces = faces[~collapsed_mask]\n",
        "faces = faces.tolist()\n",
        "scene_mesh = trimesh.Trimesh(vertices=vertices, faces=faces, force=\"mesh\",\n",
        "                        merge_primitives=True)\n",
        "scene_mesh.merge_vertices()\n",
        "scene_mesh.update_faces(scene_mesh.nondegenerate_faces())\n",
        "scene_mesh.update_faces(scene_mesh.unique_faces())\n",
        "scene_mesh.remove_unreferenced_vertices()\n",
        "scene_mesh.fix_normals()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OlaXmWZVSEQ"
      },
      "outputs": [],
      "source": [
        "del out_faces\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ALIutxzSW2DU",
        "outputId": "fafab7ce-8194-4653-f473-6ca357370ac6"
      },
      "outputs": [],
      "source": [
        "# Plot mesh from: https://colab.research.google.com/drive/1CR_HDvJ2AnjJV3Bf5vwP70K0hx3RcdMb?usp=sharing#scrollTo=kXi90AcckMF5\n",
        "\n",
        "triangles = np.asarray(scene_mesh.faces)\n",
        "vertices = np.asarray(scene_mesh.vertices)\n",
        "colors = None\n",
        "\n",
        "mesh = o3d.geometry.TriangleMesh()\n",
        "mesh.vertices = o3d.utility.Vector3dVector(vertices)\n",
        "mesh.triangles = o3d.utility.Vector3iVector(triangles)\n",
        "\n",
        "if not mesh.has_vertex_normals(): mesh.compute_vertex_normals()\n",
        "if not mesh.has_triangle_normals(): mesh.compute_triangle_normals()\n",
        "\n",
        "if mesh.has_triangle_normals():\n",
        "    colors = (0.5, 0.5, 0.5) + np.asarray(mesh.triangle_normals) * 0.5\n",
        "    colors = tuple(map(tuple, colors))\n",
        "else:\n",
        "    colors = (1.0, 0.0, 0.0)\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Mesh3d(\n",
        "            x=vertices[:,0],\n",
        "            y=vertices[:,1],\n",
        "            z=vertices[:,2],\n",
        "            i=triangles[:,0],\n",
        "            j=triangles[:,1],\n",
        "            k=triangles[:,2],\n",
        "            facecolor=colors,\n",
        "            opacity=0.50)\n",
        "    ],\n",
        "    layout=dict(\n",
        "        scene=dict(\n",
        "            xaxis=dict(visible=False),\n",
        "            yaxis=dict(visible=False),\n",
        "            zaxis=dict(visible=False)\n",
        "        )\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "sSfelqVcYbXF",
        "outputId": "ad04b074-a6b2-464c-e8d7-981eec402744"
      },
      "outputs": [],
      "source": [
        "# Save mesh if necessary\n",
        "outputFilePath=\"./output/out_\"+os.path.split(MESH_PATH)[1]\n",
        "scene_mesh.export(outputFilePath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoVn3MajeiDB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
